#!/usr/bin/env python
# -*- coding: utf-8 -*-


"""
    Developed by: Otávio Augusto Ferreira Sousa (June 2018)
    Adapted by: Raphael Rocha da Silva
    Last modified: October, 2018

    This code evaluates a summary generated by COSummarizer.py which is based on the work of Kim & Zhai(2009).
    Hyun Duk Kim and ChengXiang Zhai, Generating Comparative Summaries of Contradictory Opinions in Text, CIKM 2009

"""

from language import *
from similarity import psi, phi
from setup import *
from scipy import stats 

from pprint import pprint


def DEPREC__find_contrastive_pairs_indices():
    """
    This function fills the structure contrastive_pairs according to the generated summary given in the file PARAMETERS['SUMMARY'].
    :return: none.
    """

    with open(PARAMETERS['SUMMARY'], encoding='utf-8') as fp_summary:
        cell_length = -1
        positive_sentence, negative_sentence = '', ''
        for line_id, line in enumerate(fp_summary):
            if line_id == 0:
                cell_length = max([len(x) for x in line.split('+')])
            elif 0 < line_id <= 2:
                continue
            elif line[0] == '+':
                positive_sentence = positive_sentence.strip()
                negative_sentence = negative_sentence.strip()
                positive_id, negative_id = -1, -1
                for sentence_id, sentence in enumerate(opinion_sources['raw']['+']):
                    if sentence == positive_sentence:
                        positive_id = sentence_id
                for sentence_id, sentence in enumerate(opinion_sources['raw']['-']):
                    if sentence == negative_sentence:
                        negative_id = sentence_id
                contrastive_pairs.append((positive_id, negative_id))
                positive_sentence, negative_sentence = '', ''
            else:
                positive_sentence += line[1:(cell_length + 1)]
                negative_sentence += line[(cell_length + 2):(2 * cell_length + 2)]



# <-------------------------------------->
# <-----> COS Evaluation Functions <----->
# <-------------------------------------->


def representativeness_sim(source, summ):
    """
    The representativeness of a contrastive opinion summary S, denoted as r(S), measures how well the summary S represents the opinions expressed by the sentences in both X and Y .
    :return: [float] representativeness of the generated summary.
    """
    
    #pprint(source1)
    #for i in source1:
        #print("olha")
        #pprint(i)
        #print(i['text_info'])
    #input()
    
    source_text_info = [source[s]['text_info'] for s in source]
    
    summ_text_info = [summ[s]['text_info'] for s in [i for i in summ]] 

    score = 0

    for sX in source_text_info:
        best_value = 0
        for u in summ_text_info:
            best_value = max(best_value, phi(sX, u))
        score += best_value
        
    score /= len(source)

    return score


def contrastiveness_sim(summ1, summ2):
    """
    The contrastiveness of a contrastive opinion summary S, denoted as c(S), measures how well each u matches up with v in the summary.
    :return: [float] contrastiveness of the generated summary.
    """

    sumc = 0

    for u in summ1:
        
        p = psi(summ1[u]['text_info'], summ2[u]['text_info'])
        sumc += p
        

    return sumc / len(summ1)





      

def precision(summ1, summ2):
    """
    The precision of a summary with k contrastive sentence pairs is the percentage of the k pairs that are agreed by a human annotator. If a retrieved pair exists in an evaluator’s paired-cluster source, we assume that the pair is agreed by the annotator (i.e., “relevant”).
    :return: [float] precision of the generated summary.
    """
    
    #print()
    #pprint(summ)
    #print()
    
    c_match = 0

    for u in summ1:
        pair_is_agreed = False
        
        c1 = [i[0] for i in summ1[u]['opinions']] # gets aspects
        c2 = [i[0] for i in summ2[u]['opinions']] # gets aspects
        #c1 = getHumanClusteringForSentence(TARGET1, u['id'])
        #c2 = getHumanClusteringForSentence(TARGET2, v['id'])
        
        if any(i in c1 for i in c2):
            c_match += 1
            #print(c1)
            #print(c2)
            #print()
            

    return c_match / len(summ1)


def aspect_coverage(source, summ):
    """
    The aspect coverage of a summary is the percentage of human-aligned clusters covered in the summary. If a pair of sentences appears in a human-aligned pair of clusters, we would assume that the aligned cluster is covered.
    :return: [float] aspect coverage of the generated summary.
    """

    covered_clusters = []
    all_clusters = []
    
    # Get all possible clusters (a cluster is identified by the aspect it represents)
    
    for u in source:
        aspects = [i[0] for i in source[u]['opinions']] # gets aspects
        for a in aspects:
            if a not in all_clusters:
                all_clusters.append(a)

    
    #for product_id in human_clustering:
        #for cluster in human_clustering[product_id]:
            #if cluster not in all_clusters:
                
                ## If a cluster is in one target but not in the other, it won't be counted because it can't make pairs
                #if cluster not in human_clustering[TARGET1]:
                    #continue
                #if cluster not in human_clustering[TARGET2]:
                    #continue
                    
                #all_clusters.append(cluster)
                
     
    # Get all clusters that were covered in the summary 
    for u in summ:
        
        aspects = [i[0] for i in summ[u]['opinions']] # gets aspects
        
        for a in aspects: 
            if a not in covered_clusters:
                covered_clusters.append(a)


    return len(covered_clusters) / len(all_clusters)




## Maps pairs to original IDs. 
#def pair_to_orig_ID(pairs, IDmap1, IDmap2):
    #r = []
    #for i in pairs:
        #n = (IDmap1[i[0]], IDmap2[i[1]])
        #r.append(n)
    #return r
    
    
    
def representativiness_aspect(source, summ):
    
    points = 0
    
    opinions_source = [item for sublist in [source[j]['opinions'] for j in source] for item in sublist]
    opinions_summ = [item for sublist in [summ[j]['opinions'] for j in summ] for item in sublist]
    
    for o in opinions_source:
        for u in opinions_summ:
            if o[0] == u[0] and o[1] * u[1] >= 0:
                #print(o, u)
                points += 1
                break
    
    return points/len(opinions_source)



def contrastiviness_aspect(source, summ):
    
    points = 0
    
    opinions_source = [item for sublist in [source[j]['opinions'] for j in source] for item in sublist]
    opinions_summ = [item for sublist in [summ[j]['opinions'] for j in summ] for item in sublist]
    
    #pprint(opinions_source)
    #pprint(opinions_summ)
    
    #print()
    #print()
    #print()
    
    for o in opinions_source:
        for u in opinions_summ:
            if o[0] == u[0] and o[1] * u[1] <= 0:
                #print(o, u)
                points += 1
                break
    
    #print(points)
    return points/len(opinions_source)






